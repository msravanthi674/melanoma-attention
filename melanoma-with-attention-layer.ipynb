{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10354497,"sourceType":"datasetVersion","datasetId":6412224}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1: Setup and Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import auc, roc_auc_score\nimport warnings\nimport matplotlib.pyplot as plt\n\n# Set device to CPU or GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nwarnings.filterwarnings(\"ignore\")\n\n# Function to seed everything\ndef seed_everything(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:44:34.821608Z","iopub.execute_input":"2025-01-08T07:44:34.821933Z","iopub.status.idle":"2025-01-08T07:44:41.971808Z","shell.execute_reply.started":"2025-01-08T07:44:34.821906Z","shell.execute_reply":"2025-01-08T07:44:41.970811Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# 2: Load Dataset","metadata":{}},{"cell_type":"code","source":"# Load the dataset\n# Update the path to your dataset\nfile_path = \"/kaggle/input/dataset/marking.csv\"\ndata = pd.read_csv(file_path)\n\n# Preview the dataset\nprint(data.head())\n\n# Replace this with the actual test dataset\ntest = data.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:44:41.972859Z","iopub.execute_input":"2025-01-08T07:44:41.973455Z","iopub.status.idle":"2025-01-08T07:44:42.141238Z","shell.execute_reply.started":"2025-01-08T07:44:41.973416Z","shell.execute_reply":"2025-01-08T07:44:42.139873Z"}},"outputs":[{"name":"stdout","text":"   patient_id      image_id  target  source     sex  age_approx  \\\n0  IP_7279968  ISIC_2637011       0  ISIC20    male        45.0   \n1  IP_3075186  ISIC_0015719       0  ISIC20  female        45.0   \n2  IP_2842074  ISIC_0052212       0  ISIC20  female        50.0   \n3  IP_6890425  ISIC_0068279       0  ISIC20  female        45.0   \n4  IP_8723313  ISIC_0074268       0  ISIC20  female        55.0   \n\n  anatom_site_general_challenge  \n0                     head/neck  \n1               upper extremity  \n2               lower extremity  \n3                     head/neck  \n4               upper extremity  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# 3: Custom Dataset Class","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, transforms=None):\n        self.dataframe = dataframe\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        # Get image path and target\n        row = self.dataframe.iloc[index]\n        image_id = row['image_id']  # Reference the correct column\n        target = row['target']  # Assuming this is the target column\n        \n        # Load image (adjust path if needed)\n        image_path = f\"/kaggle/input/dataset/512x512-test/512x512-test/ISIC_0052060.jpg\"\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = Image.fromarray(image)\n\n        # Apply transformations\n        if self.transforms:\n            image = self.transforms(image)\n\n        return image, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:44:42.142761Z","iopub.execute_input":"2025-01-08T07:44:42.143255Z","iopub.status.idle":"2025-01-08T07:44:42.150335Z","shell.execute_reply.started":"2025-01-08T07:44:42.143219Z","shell.execute_reply":"2025-01-08T07:44:42.149006Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# 4: Define Transformations","metadata":{}},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create dataset and dataloader\ndataset = CustomDataset(dataframe=test, transforms=transform)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:44:42.151477Z","iopub.execute_input":"2025-01-08T07:44:42.151948Z","iopub.status.idle":"2025-01-08T07:44:42.164282Z","shell.execute_reply.started":"2025-01-08T07:44:42.151916Z","shell.execute_reply":"2025-01-08T07:44:42.163129Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# 5: Load Model","metadata":{}},{"cell_type":"code","source":"# Load a pre-trained model\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 1)  # Adjust output layer for binary classification\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:44:42.165429Z","iopub.execute_input":"2025-01-08T07:44:42.165850Z","iopub.status.idle":"2025-01-08T07:44:42.912400Z","shell.execute_reply.started":"2025-01-08T07:44:42.165804Z","shell.execute_reply":"2025-01-08T07:44:42.911271Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# 6: Inference Loop","metadata":{}},{"cell_type":"code","source":"# Dummy inference loop\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for images, _ in tqdm(dataloader):\n        images = images.to(device)\n        outputs = model(images)\n        predictions.extend(outputs.cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:44:42.914442Z","iopub.execute_input":"2025-01-08T07:44:42.914759Z","iopub.status.idle":"2025-01-08T08:46:30.759078Z","shell.execute_reply.started":"2025-01-08T07:44:42.914731Z","shell.execute_reply":"2025-01-08T08:46:30.757832Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1891/1891 [1:01:47<00:00,  1.96s/it]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# 7: Save Predictions","metadata":{}},{"cell_type":"code","source":"# Save predictions\ntest['predictions'] = predictions\ntest.to_csv(\"predictions.csv\", index=False)\n\nprint(\"Predictions saved to predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:51:34.821254Z","iopub.execute_input":"2025-01-08T08:51:34.821672Z","iopub.status.idle":"2025-01-08T08:51:39.235873Z","shell.execute_reply.started":"2025-01-08T08:51:34.821618Z","shell.execute_reply":"2025-01-08T08:51:39.235034Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to predictions.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\n# Load the predictions CSV file\npredictions = pd.read_csv(\"predictions.csv\")\n\n# Display the first few rows of the file\nprint(predictions.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:57:12.657423Z","iopub.execute_input":"2025-01-08T08:57:12.657780Z","iopub.status.idle":"2025-01-08T08:57:12.757275Z","shell.execute_reply.started":"2025-01-08T08:57:12.657751Z","shell.execute_reply":"2025-01-08T08:57:12.756252Z"}},"outputs":[{"name":"stdout","text":"   patient_id      image_id  target  source     sex  age_approx  \\\n0  IP_7279968  ISIC_2637011       0  ISIC20    male        45.0   \n1  IP_3075186  ISIC_0015719       0  ISIC20  female        45.0   \n2  IP_2842074  ISIC_0052212       0  ISIC20  female        50.0   \n3  IP_6890425  ISIC_0068279       0  ISIC20  female        45.0   \n4  IP_8723313  ISIC_0074268       0  ISIC20  female        55.0   \n\n  anatom_site_general_challenge   predictions  \n0                     head/neck  [-0.6931233]  \n1               upper extremity  [-0.6931233]  \n2               lower extremity  [-0.6931233]  \n3                     head/neck  [-0.6931233]  \n4               upper extremity  [-0.6931233]  \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}